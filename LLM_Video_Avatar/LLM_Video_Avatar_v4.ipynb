{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (2.32.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (69.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTs in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from gTTs) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from gTTs) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gTTs) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTs) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTs) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTs) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaeta\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTs) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3F3v_KlTx1nj"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "\n",
    "openai.api_key = '",
    "\n",
    "def ask_gpt(messages, max_tokens=1000, temperature=0.7, stop=None):\n",
    "  \"\"\"\n",
    "    Generate a response using OpenAI's GPT-4o model based on the provided conversation history.\n",
    "\n",
    "    Parameters:\n",
    "    - messages (list): The conversation history provided to the model.\n",
    "    - max_tokens (int): The maximum number of tokens to generate in the response.\n",
    "                        Default is 1000.\n",
    "    - temperature (float): A parameter controlling the randomness of the generated text.\n",
    "                           Lower values make the output more deterministic, while higher values introduce more randomness.\n",
    "                           Default is 0.7.\n",
    "    - stop (str or None): An optional parameter specifying tokens at which to stop generating text.\n",
    "                          Default is None.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated response stripped of leading or trailing whitespace.\n",
    "  \"\"\"\n",
    "  response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        stop=stop\n",
    "    )\n",
    "  return response.choices[0].message['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_talk(input_text, image_url):\n",
    "  \"\"\"\n",
    "    Creates a talking avatar video using the D-ID API based on the provided text and image.\n",
    "\n",
    "    Parameters:\n",
    "    input_text (str): The text to be spoken by the avatar in the video.\n",
    "    image_url (str): The URL of the image to be used as the avatar's appearance.\n",
    "\n",
    "    Returns:\n",
    "    str: the ID of the talk, otherwise None.\n",
    "\n",
    "    This function constructs a payload with the specified input text and image URL,\n",
    "    along with predefined voice settings. It then sends a POST request to the D-ID API\n",
    "    to generate a talking avatar video. The function handles the API response and\n",
    "    extracts the result URL of the video if the request is successful.\n",
    "\n",
    "    Example:\n",
    "        result_url = create_talk(\"Hello, world!\", \"https://example.com/avatar.jpg\")\n",
    "        if result_url:\n",
    "            print(\"Video URL:\", result_url)\n",
    "        else:\n",
    "            print(\"Failed to generate video.\")\n",
    "  \"\"\"\n",
    "  url = \"https://api.d-id.com/talks\"\n",
    "\n",
    "  payload = {\n",
    "      \"script\": {\n",
    "          \"type\": \"text\",\n",
    "          \"input\": input_text,\n",
    "          \"provider\": {\n",
    "              \"type\": \"microsoft\",\n",
    "              \"voice_config\": {\n",
    "                  \"style\": \"Cheerful\"\n",
    "              }\n",
    "          }\n",
    "      },\n",
    "      \"source_url\": image_url,\n",
    "      \"webhook\": \"https://eodlfa6goy5ov0o.m.pipedream.net\"\n",
    "  }\n",
    "\n",
    "  headers = {\n",
    "      \"accept\": \"application/json\",\n",
    "      \"content-type\": \"application/json\",\n",
    "      \"authorization\": \"\"\n",
    "  }\n",
    "\n",
    "  try:\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    response.raise_for_status()  # Raise an error for bad HTTP status codes\n",
    "\n",
    "    response_data = response.json()\n",
    "        \n",
    "    if 'id' in response_data:\n",
    "        return response_data['id']\n",
    "    else:\n",
    "        print(f\"Error in API response: {response_data}\")  # Log API response for debugging\n",
    "        return None\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")  # Log request exceptions\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fetch_video(id):\n",
    "  \"\"\"\n",
    "  Fetches the video URL from the given result URL using a GET request with specific headers.\n",
    "\n",
    "  Args:\n",
    "    id (str): The talk id from which the video result is to be fetched.\n",
    "\n",
    "  Returns:\n",
    "    str: The fetched video URL if successful, or an error message if the request fails.\n",
    "\n",
    "  Details:\n",
    "    - Sends a GET request to the provided URL with headers that include an acceptance of JSON response\n",
    "      and authorization credentials.\n",
    "    - If the request is successful (status code 200), it parses the JSON response to extract the video URL\n",
    "      from the 'result_url' key and returns it.\n",
    "    - If the request fails, it returns an error message indicating the failure to fetch the video.\n",
    "  \"\"\"\n",
    "  url = \"https://api.d-id.com/talks/\" + id\n",
    "  headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"authorization\": \"\"\n",
    "  }\n",
    "  time.sleep(7)\n",
    "  response = requests.get(url, headers=headers)\n",
    "  if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "    result_url = response_json.get(\"result_url\")\n",
    "    return result_url\n",
    "  else:\n",
    "    return \"Error: Unable to fetch video.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kgWZgMlz55d8"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import subprocess\n",
    "\n",
    "def video_to_audio(input_video, output_audio):\n",
    "    \"\"\"\n",
    "    Converts a video file to an audio file.\n",
    "\n",
    "    Args:\n",
    "        input_video (str): The path to the input video file.\n",
    "        output_audio (str): The desired output audio file name.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the output audio file.\n",
    "    \"\"\"\n",
    "\n",
    "    ffmpeg_path = r'C:\\Users\\gaeta\\Downloads\\ffmpeg-7.0.1-essentials_build\\ffmpeg-7.0.1-essentials_build\\bin\\ffmpeg.exe'\n",
    "\n",
    "    # Define the command to extract audio using ffmpeg\n",
    "    command = [\n",
    "        ffmpeg_path,\n",
    "        '-y',\n",
    "        '-i', input_video,\n",
    "        '-acodec', 'pcm_s16le',\n",
    "        '-q:a', '0',\n",
    "        '-map', 'a',\n",
    "        output_audio\n",
    "    ]\n",
    "    \n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE, text=True)\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"FileNotFoundError: {e}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"CalledProcessError: {e}\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "\n",
    "    return output_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zbwFoHc99cvy"
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_audio(audio_file_path):\n",
    "    \"\"\"\n",
    "    Transcribes an audio file using Google's SpeechRecognition library.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_file_path (str): Path to the audio file to be transcribed.\n",
    "\n",
    "    Returns:\n",
    "    - str: Transcribed text from the audio file.\n",
    "\n",
    "    Raises:\n",
    "    - sr.UnknownValueError: If the speech recognition cannot understand the audio.\n",
    "    - sr.RequestError: If there's an issue with the speech recognition service.\n",
    "\n",
    "    \"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Load audio file\n",
    "    audio = sr.AudioFile(audio_file_path)\n",
    "\n",
    "    # Transcribe audio\n",
    "    with audio as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Error with the service: {e}\"\n",
    "\n",
    "def audio_to_text(audio_clip):\n",
    "    \"\"\"\n",
    "    Function to handle audio file upload and transcription for Gradio interface.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_clip (str): File path to the uploaded audio clip.\n",
    "\n",
    "    Returns:\n",
    "    - str: Transcribed text from the audio file or error message if transcription fails.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = transcribe_audio(audio_clip)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error during transcription: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SV8mKCDU3n74"
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "def text_to_speech(text, filename):\n",
    "    \"\"\"\n",
    "    Converts text to speech using Google's TTS API (gTTS) and saves it to a file.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to convert to audio.\n",
    "    - filename (str): The filename to save the audio file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The file path of the saved audio.\n",
    "    \"\"\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(filename)\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "QvtD_GnuMQJB",
    "outputId": "0e6f213f-edae-4538-aac4-fbecfc927879",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Aug/2024 19:09:14] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Aug/2024 19:09:18] \"POST /save-video HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ffmpeg version 7.0.1-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, matroska,webm, from 'uploaded_video.webm':\n",
      "  Metadata:\n",
      "    encoder         : Opera\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0(eng): Audio: opus, 48000 Hz, mono, fltp (default)\n",
      "  Stream #0:1(eng): Video: vp8, yuv420p(progressive), 640x480, SAR 1:1 DAR 4:3, 1k tbr, 1k tbn (default)\n",
      "      Metadata:\n",
      "        alpha_mode      : 1\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'audio.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s (default)\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 000002127ac3a380] video:0KiB audio:248KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.030777%\n",
      "size=     248KiB time=00:00:02.63 bitrate= 768.4kbits/s speed= 381x    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Aug/2024 19:09:19] \"GET /get-audio-from-video HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Aug/2024 19:09:21] \"POST /audio-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Aug/2024 19:09:21] \"POST /ask-gpt HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: I understand you might be busy, but could you please open YouTube for me here in the office? I really need to watch a video I found about my condition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Aug/2024 19:09:22] \"POST /create-talk HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 402 Client Error: Payment Required for url: https://api.d-id.com/talks\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from flask import Flask, render_template, request, jsonify, send_file\n",
    "from threading import Thread\n",
    "import webbrowser\n",
    "\n",
    "# Initialize the Flask app\n",
    "app = Flask(__name__, template_folder=\"/Users/gaeta/OneDrive/Documents/College/Summer24/LLM_Video_Avatar/templates\")\n",
    "\n",
    "# Route to serve index.html\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def home():\n",
    "    return render_template(\"clinical_training.html\")\n",
    "\n",
    "# Endpoint to handle requests to GPT-4o\n",
    "@app.route(\"/ask-gpt\", methods=[\"POST\"])\n",
    "def ask_gpt_endpoint():\n",
    "    if request.method == \"POST\":\n",
    "        try:\n",
    "            # Get the request data\n",
    "            request_data = request.get_json()\n",
    "            if not request_data:\n",
    "                return jsonify({\"error\": \"No JSON data provided\"}), 400\n",
    "            \n",
    "            # Validate the structure of the messages\n",
    "            messages = request_data.get(\"messages\", [])\n",
    "            if not all(isinstance(m, dict) and 'role' in m and 'content' in m for m in messages):\n",
    "                print(\"Invalid messages format:\", messages)  # Log invalid format\n",
    "                return jsonify({\"error\": \"Invalid messages format\"}), 400\n",
    "\n",
    "            # Call ask_gpt function\n",
    "            response = ask_gpt(messages)\n",
    "            print(\"Generated response:\", response)  # Log generated response\n",
    "\n",
    "            return jsonify({\"response\": response})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error in processing request:\", str(e))  # Log any other errors\n",
    "            return jsonify({\"error\": \"Internal server error\"}), 500    \n",
    "\n",
    "# Endpoint to handle requests to save video file\n",
    "@app.route(\"/save-video\", methods=[\"POST\"])\n",
    "def save_video():\n",
    "    if 'video' not in request.files:\n",
    "        return \"No video file part\", 400\n",
    "    file = request.files['video']\n",
    "    if file.filename == '':\n",
    "        return \"No selected file\", 400\n",
    "    if file:\n",
    "        file.save('uploaded_video.webm')\n",
    "\n",
    "    audio_file = video_to_audio('uploaded_video.webm', 'audio.wav')\n",
    "\n",
    "    return jsonify({\"audio_file\": audio_file})\n",
    "\n",
    "# Endpoint to serve the generated audio file from the video file\n",
    "@app.route(\"/get-audio-from-video\", methods=[\"GET\"])\n",
    "def get_audio_from_video():\n",
    "    audio_file_path = 'audio.wav'\n",
    "\n",
    "    return send_file(audio_file_path, as_attachment=True)\n",
    "\n",
    "# Endpoint to transcribe audio\n",
    "@app.route(\"/audio-to-text\", methods=[\"POST\"])\n",
    "def audio_to_text_endpoint():\n",
    "    if 'audio' not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file part\"}), 400\n",
    "\n",
    "    file = request.files['audio']\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"}), 400\n",
    "\n",
    "    file_path = 'audio_for_transcribing.wav'\n",
    "    file.save(file_path)\n",
    "\n",
    "    try:\n",
    "        transcribed_text = audio_to_text(file_path)\n",
    "        return jsonify({\"transcription\": transcribed_text})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500 \n",
    "\n",
    "# Endpoint to handle requests to convert text to speech\n",
    "@app.route(\"/text-to-speech\", methods=[\"POST\"])\n",
    "def text_to_speech_endpoint():\n",
    "    if request.method == \"POST\":\n",
    "        request_data = request.get_json()\n",
    "        print(\"Received request data\", request_data)\n",
    "        \n",
    "        text = request_data.get('text')\n",
    "\n",
    "        if not text:\n",
    "            raise ValueError(\"Text not provided.\")\n",
    "\n",
    "        filename = \"response.mp3\"\n",
    "        \n",
    "        # Call function for text-to-speech conversion\n",
    "        audio_file = text_to_speech(text, filename)\n",
    "\n",
    "        return jsonify({\"audio_file\": audio_file})\n",
    "\n",
    "# Endpoint to serve the generated audio file\n",
    "@app.route(\"/get-audio\", methods=[\"GET\"])\n",
    "def get_audio():\n",
    "    # Assume you have stored the audio file path in a variable or generated it\n",
    "    audio_file_path = \"response.mp3\"\n",
    "    \n",
    "    # Return the audio file as a response\n",
    "    return send_file(audio_file_path, as_attachment=True)\n",
    "\n",
    "# Endpoint to handle requests to create D-ID video\n",
    "@app.route(\"/create-talk\", methods=[\"POST\"])\n",
    "def create_talk_endpoint():\n",
    "    image_url = \"https://photos.psychologytoday.com/1f25d4d9-4598-439e-8069-7a12ffa9012b/2/320x400.jpeg\"\n",
    "    try:\n",
    "        # Get the request data\n",
    "        request_data = request.get_json()\n",
    "        if not request_data:\n",
    "            return jsonify({\"error\": \"No JSON data provided\"}), 400\n",
    "    \n",
    "        text = request_data.get('text')\n",
    "    \n",
    "        # Call create_talk function\n",
    "        talk_id = create_talk(text, image_url)\n",
    "        if talk_id:\n",
    "            print(\"Generated response:\", talk_id)  # Log generated response\n",
    "            return jsonify({\"talk_id\": talk_id})\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Failed to create talk\"}), 500\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error in processing request:\", str(e))  # Log any other errors\n",
    "        return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "\n",
    "# Endpoint to serve the generated video file\n",
    "@app.route(\"/fetch-video\", methods=[\"GET\"])\n",
    "def fetch_video_endpoint():\n",
    "    try:\n",
    "        # Get the 'id' parameter from the query string\n",
    "        id = request.args.get('id')\n",
    "        if not id:\n",
    "            return jsonify({\"error\": \"id parameter is required\"}), 400\n",
    "\n",
    "        # Call fetch_video function\n",
    "        video_url = fetch_video(id)\n",
    "        if \"Error\" in video_url:\n",
    "            return jsonify({\"error\": video_url}), 500\n",
    "        else:\n",
    "            return jsonify({\"video_url\": video_url})\n",
    "    except Exception as e:\n",
    "        print(\"Error in processing request:\", str(e))  # Log any other errors\n",
    "        return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "\n",
    "# Endpoint to serve office_training.html\n",
    "@app.route(\"/office-training\", methods=[\"GET\"])\n",
    "def office_training():\n",
    "    return render_template(\"office_training.html\")\n",
    "\n",
    "# Endpoint to serve clinical_training.html\n",
    "@app.route(\"/clinical-training\", methods=[\"GET\"])\n",
    "def clinical_training():\n",
    "    return render_template(\"clinical_training.html\")\n",
    "\n",
    "# Function to create the proxy and run the app\n",
    "def run_app():\n",
    "    # Create the proxy\n",
    "    app.run(port=5000, debug=True, use_reloader=False)\n",
    "\n",
    "# Run the function\n",
    "thread = Thread(target=run_app)\n",
    "thread.start()\n",
    "\n",
    "webbrowser.open(\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
